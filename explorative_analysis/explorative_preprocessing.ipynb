{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may filter different features in the neural signals. Here it is investigated which preprocessing steps are suitable in this respect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from pathlib import Path\n",
    "from matplotlib.pyplot import show\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pyoptflow import HornSchunck, getimgfiles\n",
    "from pyoptflow.plots import compareGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from scipy.signal import argrelextrema\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.clip([300],0,255), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our custom utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.visualization_tools import *\n",
    "import utils.visualization_tools\n",
    "from utils.data_transformations import *\n",
    "import utils.data_transformations\n",
    "from utils.diverse import *\n",
    "import utils.diverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following modules are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_module_methods(utils.diverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_module_methods(utils.visualization_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_module_methods(utils.data_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and inspect a frame of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "source_folder = os.path.join(Path(os.getcwd()).parent, \"source_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = skimage.io.imread(os.path.join(source_folder,\"runstart16_X1.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames[:1000,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Here I calculate the difference from pixelwise mean as well as a smoothed version that promised to increase the signal to noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(frames,axis=0)#pixelwise mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = normalize(framewise_difference(frames, mean, bigdata=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = normalize(gaussian_filter(substract_pixel_min(difference), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framewise_normalized = (np.array([normalize(frame) for frame in smooth]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother = normalize(uniform_filter(framewise_normalized,[10,20,20]))# [20,30,30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = framewise_normalized-smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = np.array([normalize(frame) for frame in smooth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#details = normalize(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_enhanced = clipped_adaptive(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image enhancement and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization of the slow waves total activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth shows spreading slow waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "\n",
    "im = ax.imshow(smooth[0,:,:], vmin =.3, vmax=.5)#vmin=.25,vmax=.3)\n",
    "startframe = 70\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: im.set_array(smooth[startframe+i]), frames=30).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framewise normalization of smoothened tensor shows details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization of nuances of small scale travelling peaks in the activation by linear scaling mapping the lowest value to 0 and the highest to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "def display(frame):\n",
    "    global fig, ax\n",
    "    ax.cla()\n",
    "    im = ax.imshow(frame,vmin=0,vmax=1)#NORMALIZED FRAME HERE\n",
    "    return fig, ax\n",
    "startframe = 50\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: display(framewise_normalized[startframe+i]), frames=20).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference to the strongly smoothened tensor (in space and time) improves details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "def display(frame):\n",
    "    global fig, ax\n",
    "    ax.cla()\n",
    "    im = ax.imshow(frame)#,vmin=.1,vmax=1)\n",
    "\n",
    "    return fig, ax\n",
    "startframe = 50\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: display(details[startframe+i]), frames=20).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "def display(frame):\n",
    "    global fig, ax\n",
    "    ax.cla()\n",
    "    im = ax.imshow(frame,vmin=.0,vmax=1)#NORMALIZE ROI FRAME HERE\n",
    "    return fig, ax\n",
    "startframe = 0\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: display(contrast_enhanced[startframe+i]), frames=20).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_frame_in_roi(frame, window_size, left, right, top, bottom):   \n",
    "    further_preprocessed = exposure.equalize_adapthist(normalize(frame[left:right,top:bottom]), clip_limit=0.03)\n",
    "    further_preprocessed = further_preprocessed[:window_size-8,:window_size-8]\n",
    "    return further_preprocessed\n",
    "    \n",
    "def sample_roi(tensor, start_frame, stop_frame, window_size = 60,left = 120, top = 80,):\n",
    "    right = left + window_size\n",
    "    bottom = top + window_size\n",
    "    return np.array([sample_frame_in_roi(tensor[i], window_size, left, right, top, bottom) for i in range(start_frame,stop_frame)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"roi_background.npy\",sample_roi(frames,0,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = sample_roi(details,0,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"roi.npy\",roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "\n",
    "im = ax.imshow(smooth[0,:,:], vmin =.6, vmax=.8)\n",
    "startframe = 0\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: im.set_array(roi[startframe+i]), frames=20).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "open(\"anim.html\",\"w\").write(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to look at this:\n",
    "    - Either there are physical clusters of neurons and they talk to each other\n",
    "    - Or there are liquid informational codes and they travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there signs for systematic noise or artifacts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_decentile_roi = np.array([np.quantile(f,0.9) for f in roi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = upper_decentile_roi - gaussian_filter(upper_decentile_roi, 5)\n",
    "x, freq = fourier(signal)\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(signal-np.mean(signal))\n",
    "ax[1].plot(x,freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier plot does not indicate any dominant frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horn and Schunck dense optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comp, y_comp = horn_schunck(contrast_enhanced, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = display_combined(x_comp[0],y_comp[0], details[1])\n",
    "start = 25\n",
    "frames = 10\n",
    "\n",
    "def animate(i):\n",
    "    global start\n",
    "    i += start\n",
    "    print(\".\", end =\"\")    \n",
    "    display_combined(x_comp[i]/10,y_comp[i]/10, details[i+1], fig=fig, ax=ax)\n",
    "    #Q.set_UVC(np.flipud(rescaled[:,:,0]), -np.flipud(rescaled[:,:,1]))\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = sample_roi(details,0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comp, y_comp = horn_schunck(roi, len(roi)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = display_combined(x_comp[0],y_comp[0], details[1])\n",
    "start = 0\n",
    "frames = 10\n",
    "\n",
    "def animate(i):\n",
    "    i += start\n",
    "    print(\".\", end =\"\")    \n",
    "    display_combined(x_comp[i]/5,y_comp[i]/5, roi[i+1], fig=fig, ax=ax, scale=10, quivstep=1)\n",
    "    #Q.set_UVC(np.flipud(rescaled[:,:,0]), -np.flipud(rescaled[:,:,1]))\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "One can filter small scale motion patterns and largescale dynamics. The big size of the data represents a challange becuase of working memory restrictions when using NumPy methods directly. Custom methods can help to reduce the memory requirements. Developing scripts that run in a computational grid on computers with large memory capacities could also help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
