{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from pathlib import Path\n",
    "from matplotlib.pyplot import show\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pyoptflow import HornSchunck, getimgfiles\n",
    "from pyoptflow.plots import compareGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horn_schunck(tensor, frames=None):\n",
    "    if not frames:\n",
    "        frames = len(tensor)-1\n",
    "    x_comp = []\n",
    "    y_comp = []\n",
    "    for x in range(frames):\n",
    "        U, V = HornSchunck(tensor[x,:,:], tensor[x+1,:,:], alpha=1.0, Niter=100)\n",
    "        x_comp.append(U)\n",
    "        y_comp.append(V)\n",
    "        print(\".\",end=\"\")\n",
    "    return np.array(x_comp), np.array(y_comp)\n",
    "\n",
    "def display_combined(u, v, Inew, scale = 100, quivstep = 3, fig=None, ax=None, figsize=(10,10)):\n",
    "    if not fig:\n",
    "        fig, ax = plt.subplots(1,figsize=figsize)\n",
    "    ax.cla()\n",
    "    im = ax.imshow(Inew, vmin=.1,vmax=.2)\n",
    "\n",
    "    for i in range(0, u.shape[0], quivstep):\n",
    "        for j in range(0, v.shape[1], quivstep):\n",
    "            ax.arrow(j, i, v[i, j] * scale, u[i, j] * scale, color='red', head_width=0.5, head_length=1,)\n",
    "            \n",
    "    return fig, ax\n",
    "\n",
    "arrows = pickle.load(open(\"arrows.pkl\",\"rb\"))\n",
    "def quiver_quick(background_raw, x_comp, y_comp, block_size=16):\n",
    "    global arrows\n",
    "    background = np.ndarray([background_raw.shape[0],background_raw.shape[1],3],dtype=np.uint8)\n",
    "    background[:,:,0] = background_raw\n",
    "    background[:,:,1] = background_raw\n",
    "    background[:,:,2] = background_raw\n",
    "\n",
    "\n",
    "    \n",
    "    horizontal_blocks = y_comp.shape[1]//block_size\n",
    "    horizontal_indent = (y_comp.shape[1]%block_size)//2\n",
    "    x_mins = range(horizontal_indent,horizontal_indent+horizontal_blocks*block_size,block_size)\n",
    "    \n",
    "    vertical_blocks = y_comp.shape[0]//block_size\n",
    "    vertical_indent = (y_comp.shape[0]%block_size)//2\n",
    "    y_mins = range(vertical_indent,vertical_indent+vertical_blocks*block_size,block_size)\n",
    "    \n",
    "    \n",
    "    block = np.ones((block_size,block_size))\n",
    "    for y in y_mins:\n",
    "        for x in x_mins:\n",
    "            angle = (np.round(np.rad2deg(np.arctan2(x_comp[y,x],y_comp[y,x])/10))*10)\n",
    "\n",
    "            if angle >= 360:\n",
    "                angle -=360\n",
    "            elif angle <0:\n",
    "                angle += 360\n",
    "            \n",
    "            bg = background[y:y+block_size,x:x+block_size]\n",
    "            arrow = arrows[block_size][angle]\n",
    "            nonzero = arrow>0\n",
    "            bg[:,:,0][nonzero] = arrow[arrow>0]\n",
    "            bg[:,:,1][nonzero] -= arrow[arrow>0]\n",
    "            bg[:,:,2][nonzero] -= arrow[arrow>0]\n",
    "\n",
    "            #= arrows[block_size][angle]\n",
    "\n",
    "\n",
    "    return background  \n",
    "\n",
    "def normalize(frames):\n",
    "    frames -= np.min(frames)\n",
    "    frames /= np.max(frames)\n",
    "    return frames\n",
    "\n",
    "def normal_difference(frames, mean):\n",
    "    frames = frames - mean\n",
    "    return normalize(frames)\n",
    "\n",
    "def apply_mask(frames, mask):\n",
    "    for i, f in enumerate(frames):\n",
    "        f[mask] = 0\n",
    "        frames[i] = f\n",
    "    return frames\n",
    "\n",
    "def substract_pixel_min(tensor):\n",
    "    for y in range(tensor.shape[1]):\n",
    "        for x in range(tensor.shape[2]):\n",
    "            tensor[:,y,x] -= np.min(tensor[:,y,x])\n",
    "    return tensor\n",
    "\n",
    "def maxima(vector, pre_smoothing=100, minval=0):\n",
    "    \"\"\" Returns indices of local maxima sorted by value at each indice starting with the highest value\n",
    "    args:\n",
    "        vector: Vector of data\n",
    "        pre_smoothing: Set high values to detect substantial peaks only.\n",
    "    returns: List of local maxima\n",
    "    \"\"\"\n",
    "    extrema = None\n",
    "    if pre_smoothing > 0:\n",
    "        extrema = argrelextrema(gaussian_filter(vector,pre_smoothing),np.greater)[0]\n",
    "    else:\n",
    "        extrema = argrelextrema(vector,np.greater)[0]\n",
    "    vals = vector[extrema].flatten()\n",
    "    return extrema[vals>minval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similation of dense optical flow for growing focus of activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.zeros((50,100,100))\n",
    "tensor[20,20:60,20:60] = 1\n",
    "tensor = normalize(gaussian_filter(tensor,10))\n",
    "x_comp_sim, y_comp_sim = horn_schunck(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comp_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig_sim, ax_sim = display_combined(x_comp_sim[0],y_comp_sim[0], tensor[0])\n",
    "start = 0\n",
    "frames = 40\n",
    "\n",
    "def animate(i):\n",
    "    global start, x_comp_sim, y_comp_sim, tensor\n",
    "    i += start\n",
    "    print(\".\", end =\"\")    \n",
    "    display_combined(x_comp_sim[i], y_comp_sim[i], tensor[i+1], fig=fig_sim, ax=ax_sim)\n",
    "\n",
    "ani_sim = matplotlib.animation.FuncAnimation(fig_sim, animate, frames=frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_comp_sim[28]+y_comp_sim[28])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(ani_sim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motion vectors indicate that there is movement in the opposite direction of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test quick vector plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.ones((100,100))\n",
    "x_comp_test = np.ones((100,100))\n",
    "y_comp_test = np.ones((100,100))\n",
    "y_comp_test *= .0001\n",
    "x_comp_test *= .0001\n",
    "y_comp_test[0:50,0:50] = 1*.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.ones((100,100))\n",
    "x_comp_test = -np.ones((100,100))\n",
    "y_comp_test = -np.ones((100,100))\n",
    "y_comp_test *= .0001\n",
    "x_comp_test *= .0001\n",
    "y_comp_test[0:50,0:50] = 1*.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 40\n",
    "plt.imshow(quiver_quick(mat.copy()*255,x_comp_test, y_comp_test,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(1, figsize=(5,5))\n",
    "display_combined(x_comp_test, y_comp_test, mat, fig=f, ax=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 20\n",
    "plt.imshow(quiver_quick(tensor[frame,:,:].copy()*128,x_comp_sim[frame,:,:], y_comp_sim[frame,:,:],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(1, figsize=(6,6))\n",
    "display_combined(x_comp_sim[frame,:,:], y_comp_sim[frame,:,:], tensor[frame,:,:].copy()*255, fig=f, ax=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect a frame of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "source_folder = os.path.join(Path(os.getcwd()).parent, \"source_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = skimage.io.imread(os.path.join(source_folder,\"runstart16_X1.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames[:2000,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Here I calculate the difference from pixelwise mean as well as a smoothed version that promised to increase the signal to noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(frames,axis=0)#pixelwise mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = normal_difference(frames, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = normalize(gaussian_filter(substract_pixel_min(difference), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother = normalize(gaussian_filter(substract_pixel_min(difference), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = smooth-smoother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the mean of frames in time\n",
    "\n",
    "- Is there a systematic error/trend in the timeseries?\n",
    "\n",
    "- Could the short wave events be identified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_means = [np.mean(f) for f in smooth]\n",
    "frame_max = [np.max(f) for f in smooth]\n",
    "upper_decentile = [np.quantile(f,0.9) for f in smooth]\n",
    "smooth_max = gaussian_filter(frame_max,10)\n",
    "smoother_max = gaussian_filter(frame_max,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = maxima(np.array(smoother_max),0,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1,figsize=(10,10))\n",
    "ax.plot(frame_means, label=\"mean\")\n",
    "ax.plot(frame_max, label=\"max\")\n",
    "ax.plot(upper_decentile, label = \"upper decentile\")\n",
    "ax.plot(smoother_max, label=\"smooth max\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel(\"frame\")\n",
    "ax.set_ylabel(\"value\")\n",
    "for x in maxs:\n",
    "    ax.axvline(x, c=\"lightgray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_peaks(vector, threshold):\n",
    "    vector = np.array(vector) > threshold\n",
    "    prev_val = vector[0]\n",
    "    count = 0\n",
    "    for x in vector[1:]:\n",
    "        if prev_val != x:#If previous value was different (e.g. False and now we have True)\n",
    "            count += 1\n",
    "            prev_val = x\n",
    "    \n",
    "    return (count)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_for_thresholds = [count_peaks(smooth_max,x) for x in np.arange(100)/100]\n",
    "plt.plot(np.linspace(0,1,100),peaks_for_thresholds)\n",
    "print(np.where(peaks_for_thresholds==np.max(peaks_for_thresholds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(upper_decentile, frame_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no systematic error (trend) for the timeseries of activation (luminance difference from mean).\n",
    "\n",
    "The upper decentile and the maximal value correlate strongly. The images are not affected by single pixel outliers (non-gaussian noise). Hence, a strategy of detecting slow-wave events based on (local maxima of) maximal values appears feasable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect smooth version and determine feasable thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization of the slow waves total activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "\n",
    "im = ax.imshow(smooth[0,:,:], vmin =.1, vmax=.2)#vmin=.25,vmax=.3)\n",
    "startframe = 50\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: im.set_array(smooth[startframe+i]), frames=150).to_jshtml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization of nuances of small scale travelling peaks in the activation by linear scaling mapping the lowest value to 0 and the highest to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "def display(frame):\n",
    "    global fig, ax\n",
    "    ax.cla()\n",
    "    im = ax.imshow(normalize(frame),vmin=0,vmax=1)\n",
    "    return fig, ax\n",
    "startframe = 50\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: display(smooth[startframe+i]), frames=150).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "def display(frame):\n",
    "    global fig, ax\n",
    "    ax.cla()\n",
    "    im = ax.imshow(frame,vmin=.0,vmax=1)\n",
    "    return fig, ax\n",
    "startframe = 50\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: display(details[startframe+i]), frames=150).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horn and Schunck dense optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comp, y_comp = horn_schunck(details, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = display_combined(x_comp[0],y_comp[0], details[1])\n",
    "start = 50\n",
    "frames = 100\n",
    "\n",
    "def animate(i):\n",
    "    global start\n",
    "    i += start\n",
    "    print(\".\", end =\"\")    \n",
    "    display_combined(x_comp[i],y_comp[i], details[i+1], fig=fig, ax=ax)\n",
    "    #Q.set_UVC(np.flipud(rescaled[:,:,0]), -np.flipud(rescaled[:,:,1]))\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for maximal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = maxs#maxima(np.mean(np.mean(smooth,axis=1),axis=1),2,.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = smooth[idxs[3]]\n",
    "plt.imshow(frame, vmin=.1, vmax=.5)\n",
    "max_loc = np.where(frame == np.max(frame))\n",
    "plt.scatter(max_loc[1],max_loc[0], marker=\"x\", c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for idx in idxs:\n",
    "    frame = smooth[idx]\n",
    "    max_loc = np.where(frame == np.max(frame))\n",
    "    xs.extend(max_loc[1])\n",
    "    ys.extend(max_loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,20))\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(mean)\n",
    "ax[0].scatter(xs, ys, marker=\"x\", c=\"red\")\n",
    "ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like secondary visial cortices and motor cortices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2\n",
    "\n",
    "Assumption: The earliest detectable region of a beginning peak in activation relates to it's origin \n",
    "\n",
    "Additional assumption: If there is more then one region even at the beginning of neural activity one could additionally assume that the area with the strongest activation is the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "class FastDensityClustering():\n",
    "    @staticmethod\n",
    "    def gaussian_kernel(size=21, nsig=3):\n",
    "        \"\"\"Returns a 2D Gaussian kernel.\n",
    "        Args:\n",
    "            size: The size of the kernel (size x size)\n",
    "            nsig: Sigma of the gaussian\n",
    "        \"\"\"\n",
    "        x = np.linspace(-nsig, nsig, size+1)\n",
    "        kern1d = np.diff(st.norm.cdf(x))\n",
    "        kern2d = np.outer(kern1d, kern1d)\n",
    "        return kern2d/kern2d.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def kernel(size, ktype):\n",
    "        \"\"\" Returns a kernel of specified size and type\n",
    "        Args:\n",
    "            size: Kernel size\n",
    "            ktype: Type of kernel. Either uniform gaussian or disk are provided.\n",
    "        \"\"\"\n",
    "        if ktype == \"uniform\":\n",
    "            return np.ones((size,size))\n",
    "        elif ktype == \"gaussian\":\n",
    "            k = FastDensityClustering.gaussian_kernel(size=size)\n",
    "            k /= np.max(k)\n",
    "            return k\n",
    "        elif ktype == \"disk\":\n",
    "            k = FastDensityClustering.gaussian_kernel(size=size)\n",
    "            k /= np.max(k)\n",
    "            return k > 0.03\n",
    "\n",
    "    @staticmethod\n",
    "    def collapse_iteration(arr,kernel):\n",
    "        \"\"\" Determins center of gravity for each non-zero (forground pixel) and it's surround weighted by the kernel\n",
    "            and increases mass at named target position/pixel by the mass of the source pixel.\n",
    "        Args:\n",
    "            arr: Grayscale array of positive values where value zero stands for the background and positive values denote the mass for a given foreground pixel.\n",
    "            kernel: Kernel used to weight the influance of nearby pixels in computing the center of mass\n",
    "        \"\"\"\n",
    "        kernel_width = kernel.shape[0]\n",
    "        kernel_height = kernel.shape[1]\n",
    "        ys, xs = np.where(arr>0)\n",
    "        new = np.zeros(arr.shape)\n",
    "        abs_shift = 0\n",
    "\n",
    "        mapping = {}\n",
    "        for y, x in zip(ys,xs):\n",
    "            snippet = arr[y-kernel_width//2:(y+kernel_width//2)+1, x-kernel_width//2:(x+kernel_width//2)+1]\n",
    "\n",
    "            snippet = kernel * snippet\n",
    "            weights_x = np.mean(snippet,axis=0)\n",
    "            weights_y = np.mean(snippet,axis=1)\n",
    "\n",
    "            shift_x = np.average(np.arange(kernel_width),weights=weights_x)#The inner mean returns x values, the outer is their mean -> shift x\n",
    "            shift_y = np.average(np.arange(kernel_height),weights=weights_y)#The inner mean returns y values, the outer is their mean -> shift y\n",
    "            shift_x -= (kernel_width-1)/2\n",
    "            shift_y -= (kernel_height-1)/2\n",
    "\n",
    "\n",
    "            y1 = int(y+shift_y)\n",
    "            x1 = int(x+shift_x)\n",
    "\n",
    "            #Remember where the contribution of the mass of the tatget comes from\n",
    "            if y1 != y or x1 != x:\n",
    "                if not str([y1,x1]) in mapping:\n",
    "                    mapping[str([y1,x1])] = []\n",
    "                mapping[str([y1,x1])] = [y,x]\n",
    "\n",
    "            abs_shift += np.abs(shift_x) + np.abs(shift_y)\n",
    "            new[y1,x1] += arr[y,x]\n",
    "        if len(xs) > 0:\n",
    "            shift = abs_shift/len(xs)\n",
    "        else:\n",
    "            shift = 0\n",
    "        return new, shift, mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def collapse(arr, iterations = None,gravity_type=\"uniform\", gravity_size=5):\n",
    "        \"\"\" Performs clustering by iteratively moving all mass densities (non-zero/foreground pixels) to their center of mass.\n",
    "        If no value for iterations is specified the algorithm runs until convergence is achieved and the movement is marginally.\n",
    "        Args:\n",
    "            arr: Array of positive gray values\n",
    "            iterations: Number of iterations. If no value for iterations is specified the algorithm runs until convergence is achieved.\n",
    "            gravity_type: Either \"uniform\", \"gaussian\" or \"disk\". The contributions to the center of mass for one pixels by its surround are weighted accordingly.\n",
    "            gravity_size: The size of the gravity kernel.\n",
    "        Returns:\n",
    "            Array representation of cluster centers. Each cluster center is represented by a non-zero pixel.\n",
    "        \"\"\"\n",
    "        epsilon = None\n",
    "        if not iterations:\n",
    "            iterations = 1000\n",
    "            epsilon = 1.0e-16\n",
    "\n",
    "        if gravity_size % 2 == 0:\n",
    "            gravity_size += 1\n",
    "        k = FastDensityClustering.kernel(gravity_size,gravity_type)\n",
    "        arr = np.pad(arr,gravity_size, \"constant\")\n",
    "        mappings = []\n",
    "        for x in range(iterations):\n",
    "            arr, shift, mapping = FastDensityClustering.collapse_iteration(arr,k)\n",
    "            mappings.append(mapping)\n",
    "            if epsilon:\n",
    "                if epsilon > shift:\n",
    "                    break\n",
    "\n",
    "\n",
    "        return arr[gravity_size:-gravity_size,gravity_size:-gravity_size], mappings\n",
    "\n",
    "    @staticmethod\n",
    "    def density_clustering(arr, iterations = None, gravity_type=\"uniform\", gravity_size=5):\n",
    "        \"\"\" Performs clustering by iteratively moving all mass densities (non-zero/foreground pixels) to their center of mass.\n",
    "        If no value for iterations is specified the algorithm runs until convergence is achieved and the movement is marginally.\n",
    "        Args:\n",
    "            arr: Array of positive gray values\n",
    "            iterations: Number of iterations. If no value for iterations is specified the algorithm runs until convergence is achieved.\n",
    "            gravity_type: Either \"uniform\", \"gaussian\" or \"disk\". The contributions to the center of mass for one pixels by its surround are weighted accordingly.\n",
    "            gravity_size: The size of the gravity kernel.\n",
    "        Returns:\n",
    "            Y and x positions of all detected cluster centers\n",
    "        \"\"\"\n",
    "        cluster_array, mappings = FastDensityClustering.collapse(arr,iterations,gravity_type=gravity_type, gravity_size=gravity_size)\n",
    "        center_y,center_x = np.where(cluster_array>0)\n",
    "        print(\".\",end=\"\")\n",
    "        return center_y, center_x, cluster_array, mappings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask out values based on a threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find frames that correspond to early stages of spreading neural activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded = smooth.copy()\n",
    "thresholded[thresholded <.15] = 0\n",
    "thresholded = normalize(thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_thresholded = np.mean(np.mean(thresholded, axis=1),axis=1)\n",
    "maxs_thresholded = maxima(np.mean(np.mean(smooth,axis=1),axis=1),2,.15)\n",
    "\n",
    "event_start_idxs = []\n",
    "event_active = False\n",
    "for i, v in enumerate(mean_thresholded>.001):\n",
    "    if v and not event_active:\n",
    "        event_active = True\n",
    "        event_start_idxs.append(i)\n",
    "    if not v:\n",
    "        event_active = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_max = 600\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.plot(mean_thresholded[:idx_max])\n",
    "plt.plot((mean_thresholded[:idx_max]>.001)/10)\n",
    "for x in event_start_idxs:\n",
    "    if x > idx_max:\n",
    "        continue\n",
    "    ax.axvline(x, c=\"lightgray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use fast density clustering to find clustercenters of strongest activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 13\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "frame = normalize(thresholded[event_start_idxs[idx]])>.95\n",
    "res = FastDensityClustering.density_clustering(frame,gravity_size=40)\n",
    "ax.imshow(smooth[event_start_idxs[idx]], vmin=.0, vmax=.5)\n",
    "ax.scatter(np.where(frame)[1],np.where(frame)[0])\n",
    "ax.scatter(res[1],res[0], marker=\"x\", color=\"red\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With additional assumption (strongest activation cluster is origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "xs = []\n",
    "for event_start_idx in event_start_idxs:\n",
    "    frame = normalize(thresholded[event_start_idx])>.95\n",
    "    res = FastDensityClustering.density_clustering(frame,gravity_size=10)\n",
    "    center_density = res[2][res[:2]]#The density of the points that collapsed to named cluster center\n",
    "    heviest_center = np.where(center_density == np.max(center_density))      \n",
    "    ys.extend(res[0][heviest_center])\n",
    "    xs.extend(res[1][heviest_center])\n",
    "    #ys.extend(res[0])\n",
    "    #xs.extend(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean)\n",
    "plt.scatter(xs, ys, marker=\"x\", c=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without additional assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "xs = []\n",
    "for event_start_idx in event_start_idxs:\n",
    "    frame = normalize(thresholded[event_start_idx])>.95\n",
    "    res = FastDensityClustering.density_clustering(frame,gravity_size=10)\n",
    "    ys.extend(res[0])\n",
    "    xs.extend(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,20))\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(mean)\n",
    "ax[0].scatter(xs, ys, marker=\"x\", c=\"red\")\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(Image.open(\"cortex.bmp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks again like the source of activation stems from secondary visial cortices and motor cortices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(15,15))\n",
    "ax.axis('off')\n",
    "ax.imshow(Image.open(\"with_boundaries.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible analysis with ANNs\n",
    "- Predict location based on history of locations for previous events using regression MLPs. Are there regulrities?\n",
    "- Predict next frame with previous frame using autoencoder?\n",
    "- Predict experimental condition using some characteristic of the signal slope (e.g. mean per frame)?\n",
    "- Go into direction of spiking neural networks/ biological models for neural networks?\n",
    "- Use information about anatomical connectivity & initial activation to predict activation of later frames. Compare to prediction using initial activation only. Could the prediction be improved when considering anatomical conncectivity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "- Kirkcaldie, M. T. K., Watson, C., Paxinos, G., & Franklin, K. (2012). Straightening out the mouse neocortex. In Australian Neuroscience Society Annual Conference. Available online via https://www.researchgate.net/profile/Matthew_Kirkcaldie/publication/234062488_Straightening_out_the_mouse_neocortex/links/09e4150ef5c5a1214d000000/Straightening-out-the-mouse-neocortex.pdf.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
