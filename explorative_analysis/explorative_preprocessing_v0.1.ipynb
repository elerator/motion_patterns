{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may filter different features in the neural signals. Here it is investigated which preprocessing steps are suitable in this respect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from pathlib import Path\n",
    "from matplotlib.pyplot import show\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pyoptflow import HornSchunck, getimgfiles\n",
    "from pyoptflow.plots import compareGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from scipy.signal import argrelextrema\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.clip([300],0,255), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"mask.png\"))[:,:,0] == 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(apply_mask(np.array(frames[0:2], dtype=np.double), mask, nan=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our custom utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.visualization_tools import *\n",
    "import utils.visualization_tools\n",
    "from utils.data_transformations import *\n",
    "import utils.data_transformations\n",
    "from utils.diverse import *\n",
    "import utils.diverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following modules are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_module_methods(utils.diverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_module_methods(utils.visualization_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_module_methods(utils.data_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and inspect a frame of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "source_folder = os.path.join(Path(os.getcwd()).parent, \"datasets/source_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = skimage.io.imread(os.path.join(source_folder,\"runstart16_X1.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(exposure.equalize_adapthist(normalize(np.mean(frames[:100,:,:],axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames[:1000,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Here I calculate the difference from pixelwise mean as well as a smoothed version that promised to increase the signal to noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(frames,axis=0)#pixelwise mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = normalize(framewise_difference(frames, mean, bigdata=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some pixels are always brighter even at baseline activity. As the depiction below reveals one reason for this is bloodflow. Another reason is arguably a random pixel bias due to the camera. As we are interested in neither of these signals we aim at removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(np.min(difference,axis=0))\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Pixelwise minimum\")\n",
    "ax[1].imshow(np.quantile(difference,.02,axis=0))\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"2nd percentile per pixelvector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth = normalize(gaussian_filter(difference, 1))#Contaminated with bloodflow signal; remove later\n",
    "#smooth = normalize(gaussian_filter(substract_pixel_min(difference, quantile=.1), 1))\n",
    "smooth = normalize(gaussian_filter(substract_pixel_min(difference), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeat_filtered = remove_frequency_from_pixel_vectors(smooth,16,18)\n",
    "\n",
    "#smooth = heartbeat_filtered#TODO REMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framewise_normalized = (np.array([normalize(frame) for frame in heartbeat_filtered]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the difference from the spreading slow waves the difference between the strongly smoothened signal and the original signal (smooth) is being computed. A 3D gaussian kernel is used in this respect. For the time dimension only one slice is considered to calculate the stongly smoothened signal as the impact of a beginning slow wave would otherwise manifest in the resulting signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother = normalize(uniform_filter(heartbeat_filtered,[0,60,60]))#[1,10,10]))# [20,30,30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(uniform_filter(framewise_normalized,[1,50,50])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = heartbeat_filtered-smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass = [lowpass_filter(im,\"vertical\") for im in details]\n",
    "details = np.array([normalize(frame) for frame in details])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = normalize(details)\n",
    "lowpass = normalize(lowpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_enhanced = clipped_adaptive(framewise_normalized,.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image enhancement and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization of the slow waves total activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth shows spreading slow waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "\n",
    "im = ax.imshow(smooth[0,:,:], vmin =.3, vmax=.5)#vmin=.25,vmax=.3)\n",
    "startframe = 70\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: im.set_array(smooth[startframe+i]), frames=20).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the heartbeat & retrieve bloodflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeat = gaussian_filter(np.mean(smooth, axis = (1,2))-gaussian_filter(np.mean(smooth, axis = (1,2)),3),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(10,10))\n",
    "ax[0].set_title(\"Filtered heartbeat signal\")\n",
    "for x in maxima(heartbeat, pre_smoothing=0):\n",
    "    ax[0].axvline(x, c=\"lightgray\")\n",
    "ax[0].plot(heartbeat)\n",
    "\n",
    "ax[1].plot(*fourier(heartbeat))\n",
    "ax[1].set_xticks(np.arange(0, 100+1, 5))\n",
    "\n",
    "ax[1].set_title(\"Frequencies (FFT)\")\n",
    "ax[2].plot(*remove_frequency(heartbeat, 16, 18)[1:])\n",
    "ax[2].set_title(\"Filtered frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeat_in_space = normalize(heartbeat_filtered-smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeat_peaks = maxima(heartbeat, pre_smoothing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ani = show_video(heartbeat_in_space[:,120:180,80:140],n_frames=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = clipped_adaptive(heartbeat_in_space[:,120:180,80:140])[:,:-8,:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean over a few heartbeats \n",
    "vessels = np.array([exposure.equalize_adapthist(np.mean(ca[i:200+i:12,:,:],axis=0))[:-8,:-8] for i in range(12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ani = show_video(vessels,ca, n_frames=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"bloodflow.npy\", ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive histogram equalization (left) and clipping of equalized signal (right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_period = 12\n",
    "out = np.zeros([n_period,heartbeat_in_space.shape[1],heartbeat_in_space.shape[2]])\n",
    "for x in heartbeat_peaks[1:-1]:\n",
    "    out[:,:,:] += heartbeat_in_space[x-n_period//2:x+n_period//2,:,:]\n",
    "out/=len(heartbeat_peaks[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ani = show_video(normalize(out),n_frames=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comp, y_comp = horn_schunck(heartbeat_in_space[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = display_combined(x_comp[0],y_comp[0], details[1])\n",
    "start = 0\n",
    "frames = 22\n",
    "\n",
    "def animate(i):\n",
    "    global start\n",
    "    i += start\n",
    "    print(\".\", end =\"\")    \n",
    "    display_combined(y_comp[i],x_comp[i], heartbeat_in_space[i+1], fig=fig, ax=ax)\n",
    "    #Q.set_UVC(np.flipud(rescaled[:,:,0]), -np.flipud(rescaled[:,:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=frames).to_jshtml()\n",
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desired: A method of how one could average over vector fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use upper percentiles per frame only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_percentiles = [np.quantile(img, .9) for img in smooth]\n",
    "percentile_thresholded = smooth[:,:,:].copy()\n",
    "epsilon = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_percentile_heartbeat = np.mean(percentile_thresholded,axis=(1,2))\n",
    "upper_percentile_heartbeat -= gaussian_filter(upper_percentile_heartbeat, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(upper_percentile_heartbeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, threshold in enumerate(upper_percentiles):\n",
    "    percentile_thresholded[i][percentile_thresholded[i] < threshold] = threshold\n",
    "    percentile_thresholded[i][percentile_thresholded[i] > threshold+epsilon] = threshold+epsilon\n",
    "    percentile_thresholded[i] = normalize(percentile_thresholded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "vid = show_video(percentile_thresholded, n_frames = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framewise normalization of smoothened tensor shows details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization of nuances of small scale travelling peaks in the activation by linear scaling mapping the lowest value to 0 and the highest to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "def display(frame):\n",
    "    global fig, ax\n",
    "    ax.cla()\n",
    "    im = ax.imshow(frame,vmin=0,vmax=1)#NORMALIZED FRAME HERE\n",
    "    return fig, ax\n",
    "startframe = 50\n",
    "ani = matplotlib.animation.FuncAnimation(fig, lambda i: display(framewise_normalized[startframe+i]), frames=20).to_jshtml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference to the strongly smoothened tensor (in space and time) improves details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ani = show_video(details, lowpass, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = normalize(np.mean(lowpass,axis=0))\n",
    "img = contrast_enhanced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "startframe = 0\n",
    "n_frames = 200\n",
    "superimposed = [superimpose(a,b, cm.gray, cm.viridis) for a,b in zip(contrast_enhanced[startframe:startframe+n_frames],\n",
    "                                                                          lowpass[startframe:startframe+n_frames])]\n",
    "frame_selection = smooth[startframe:startframe+n_frames].copy()\n",
    "frame_selection[frame_selection<.3] = .3\n",
    "frame_selection[frame_selection>.5] = .5\n",
    "frame_selection = normalize(frame_selection)\n",
    "\n",
    "ani = show_video(superimposed, frame_selection, 200, orient=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2)\n",
    "signal = np.mean(contrast_enhanced,axis=(1,2))\n",
    "signal -= gaussian_filter(signal,1)\n",
    "ax[0].plot(signal)\n",
    "ax[1].plot(*fourier(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal contains mostly high frequency components. The peak in frequency at around 16 Hz that corresponds to the heartbeat is absent. Spatially the filtered clusters do not preferably overlap with the low frequency signal that is low-pass-filtered from the detail images (smooth minus smoother). Both can be considered as an indicator that the filtered signal does not predominantly correspond to blood that moves at a uniform speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_frame_in_roi(frame, window_size, left, right, top, bottom):   \n",
    "    snippet = frame[left:right,top:bottom]\n",
    "    further_preprocessed = exposure.equalize_adapthist(normalize(snippet), clip_limit=0.03)\n",
    "    further_preprocessed = further_preprocessed[:window_size-8,:window_size-8]\n",
    "    return further_preprocessed\n",
    "    \n",
    "def sample_roi(tensor, start_frame, stop_frame, window_size, left, top):\n",
    "    right = left + window_size\n",
    "    bottom = top + window_size\n",
    "    return np.array([sample_frame_in_roi(tensor[i], window_size, left, right, top, bottom) for i in range(start_frame,stop_frame)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"roi_background.npy\",sample_roi(frames,0,300, 60, 120, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "roi = sample_roi(details,0, 300, 60, 120, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"roi.npy\",roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "roi1 = clipped_adaptive(heartbeat_in_space[:300,120:120+window_size,80:80+window_size])[:,:52,:52]\n",
    "\n",
    "clipped_roi = roi.copy()\n",
    "clipped_roi[clipped_roi>.8] = .8\n",
    "clipped_roi[clipped_roi<.6] = .6\n",
    "clipped_roi = normalize(clipped_roi)\n",
    "ani = show_video(clipped_roi,roi1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(show_video([normalize(np.log(f)) for f in heartbeat_in_space[:300,120:120+window_size,80:80+window_size]],\n",
    "               [normalize(f) for f in smooth[:300,120:120+window_size,80:80+window_size]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef(heartbeat_in_space[:300,120:120+window_size,80:80+window_size].flatten(),\n",
    "            details[:300,120:120+window_size,80:80+window_size].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heartbeat_in_space[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(roi.flatten(), gaussian_filter(roi1,1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_of_means = np.corrcoef(np.mean(clipped_roi,axis=0),np.mean(roi1,axis=0))\n",
    "corr_of_means = corr_of_means[len(corr_of_means)//2:,:len(corr_of_means)//2]\n",
    "plt.imshow(corr_of_means)\n",
    "plt.colorbar()\n",
    "print(np.mean(np.abs(corr_of_means)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there signs for systematic noise or artifacts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_decentile_roi = np.array([np.quantile(f,0.9) for f in roi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = upper_decentile_roi - gaussian_filter(upper_decentile_roi, 5)\n",
    "x, freq = fourier(signal)\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(signal-np.mean(signal))\n",
    "ax[1].plot(x,freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier plot does not indicate any dominant frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horn and Schunck dense optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comp, y_comp = horn_schunck(contrast_enhanced, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = display_combined(x_comp[0],y_comp[0], details[1])\n",
    "start = 25\n",
    "frames = 10\n",
    "\n",
    "def animate(i):\n",
    "    global start\n",
    "    i += start\n",
    "    print(\".\", end =\"\")    \n",
    "    display_combined(y_comp[i]/10,x_comp[i]/10, details[i+1], fig=fig, ax=ax)\n",
    "    #Q.set_UVC(np.flipud(rescaled[:,:,0]), -np.flipud(rescaled[:,:,1]))\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = sample_roi(details,0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comp, y_comp = horn_schunck(roi, len(roi)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = display_combined(x_comp[0],y_comp[0], details[1])\n",
    "start = 0\n",
    "frames = 10\n",
    "\n",
    "def animate(i):\n",
    "    i += start\n",
    "    print(\".\", end =\"\")    \n",
    "    display_combined(x_comp[i]/5,y_comp[i]/5, roi[i+1], fig=fig, ax=ax, scale=10, quivstep=1)\n",
    "    #Q.set_UVC(np.flipud(rescaled[:,:,0]), -np.flipud(rescaled[:,:,1]))\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "One can filter small scale motion patterns and largescale dynamics. The big size of the data represents a challange becuase of working memory restrictions when using NumPy methods directly. Custom methods can help to reduce the memory requirements. Developing scripts that run in a computational grid on computers with large memory capacities could also help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
